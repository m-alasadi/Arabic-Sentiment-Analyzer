"""
Arabic Sentiment Analysis Dashboard
Streamlit-based web application for analyzing sentiment of Arabic social media comments and news.
"""

import sys
import os
import traceback
import warnings
from datetime import datetime
from typing import List, Dict, Any
import io

# Suppress warnings
warnings.filterwarnings('ignore')

# Import Streamlit first
try:
    import streamlit as st
except ImportError as e:
    print(f"ERROR: Streamlit not installed. Run: pip install streamlit")
    sys.exit(1)

# Import data processing libraries
try:
    import pandas as pd
except ImportError as e:
    st.error("ERROR: pandas not installed. Run: pip install pandas")
    st.stop()

# Import local modules
try:
    from analyzer import SentimentAnalyzer
    from scraper import fetch_api_comments, scrape_hashtag_news
except ImportError as e:
    st.error(f"ERROR: Failed to import local modules. {str(e)}")
    st.stop()

# Configure Streamlit page (MUST be first Streamlit call)
try:
    st.set_page_config(
        page_title="Arabic Sentiment Analysis Dashboard",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
except Exception as e:
    print(f"ERROR: Failed to configure Streamlit page: {str(e)}")
    sys.exit(1)

# Custom styling
st.markdown("""
    <style>
    .main-header {
        text-align: center;
        color: #1f77b4;
    }
    .stDataFrame {
        width: 100%;
    }
    .metric-box {
        padding: 10px;
        border-radius: 5px;
        background-color: #f0f2f6;
    }
    .sentiment-positive {
        color: #28a745;
        font-weight: bold;
    }
    .sentiment-negative {
        color: #dc3545;
        font-weight: bold;
    }
    .sentiment-neutral {
        color: #ffc107;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)


@st.cache_resource
def load_analyzer() -> SentimentAnalyzer:
    """Load the sentiment analyzer model (cached for performance)."""
    try:
        model_path = "./my_final_expert_model_v3"
        
        # Verify model path exists
        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"Model directory not found at: {os.path.abspath(model_path)}\n"
                f"Current working directory: {os.getcwd()}"
            )
        
        # Load the model
        analyzer = SentimentAnalyzer(model_path=model_path)
        return analyzer
        
    except FileNotFoundError as e:
        st.error(f"âŒ Model Error: {str(e)}")
        st.stop()
    except ImportError as e:
        st.error(f"âŒ Import Error - Missing dependency: {str(e)}")
        st.error("Run: pip install -r requirements.txt")
        st.stop()
    except Exception as e:
        st.error(f"âŒ Unexpected Error: {str(e)}")
        st.error(traceback.format_exc())
        st.stop()


def process_comments(comments: List[Any], analyzer: SentimentAnalyzer) -> List[Dict[str, Any]]:
    """
    Process comments and analyze their sentiment.
    
    Args:
        comments (List[Any]): List of comments (strings or dicts with 'text' key).
        analyzer (SentimentAnalyzer): Sentiment analyzer instance.
        
    Returns:
        List[Dict[str, Any]]: List of analysis results with comments and sentiments.
    """
    if not comments:
        st.error("âŒ No comments to process")
        return []
    
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, comment in enumerate(comments):
        try:
            # Handle both string and dict formats
            if isinstance(comment, dict):
                clean_comment = comment.get('text', '').strip()
                source = comment.get('source', 'Unknown')
            else:
                clean_comment = comment.strip() if isinstance(comment, str) else str(comment).strip()
                source = 'Unknown'
            
            if not clean_comment:
                continue
            
            # Analyze sentiment
            sentiment = analyzer.analyze_text(clean_comment)
            
            results.append({
                "Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ (Comment)": clean_comment,
                "Ø§Ù„Ù…ØµØ¯Ø± (Source)": source,
                "Ø§Ù„ØªØµÙ†ÙŠÙ (Label)": sentiment['label'],
                "Ø§Ù„Ø«Ù‚Ø© (Score)": sentiment['score'],
            })
            
            # Update progress
            progress = (idx + 1) / len(comments)
            progress_bar.progress(progress)
            status_text.text(f"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª... {idx + 1}/{len(comments)}")
        
        except Exception as e:
            st.warning(f"âš  Error processing comment #{idx + 1}: {str(e)}")
            continue
    
    progress_bar.empty()
    status_text.empty()
    
    return results


def process_news_articles(articles: List[Dict[str, Any]], analyzer: SentimentAnalyzer) -> List[Dict[str, Any]]:
    """
    Process news articles and analyze their sentiment.
    
    Args:
        articles (List[Dict[str, Any]]): List of article dicts with 'text' and 'source'.
        analyzer (SentimentAnalyzer): Sentiment analyzer instance.
        
    Returns:
        List[Dict[str, Any]]: List of analysis results with articles and sentiments.
    """
    if not articles:
        st.error("âŒ No articles to process")
        return []
    
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, article in enumerate(articles):
        try:
            # Extract text and source
            text = article.get('text', '').strip() if isinstance(article.get('text'), str) else ''
            source = article.get('source', '').strip() if isinstance(article.get('source'), str) else ''
            
            if not text:
                continue
            
            # Analyze sentiment
            sentiment = analyzer.analyze_text(text)
            
            results.append({
                "Ø§Ù„Ø®Ø¨Ø± (Headline)": text,
                "Ø§Ù„Ù…ØµØ¯Ø± (Source)": source,
                "Ø§Ù„ØªØµÙ†ÙŠÙ (Label)": sentiment['label'],
                "Ø§Ù„Ø«Ù‚Ø© (Score)": sentiment['score'],
            })
            
            # Update progress
            progress = (idx + 1) / len(articles)
            progress_bar.progress(progress)
            status_text.text(f"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø±... {idx + 1}/{len(articles)}")
        
        except Exception as e:
            st.warning(f"âš  Error processing article #{idx + 1}: {str(e)}")
            continue
    
    progress_bar.empty()
    status_text.empty()
    
    return results


def create_summary_stats(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Create summary statistics from analysis results.
    
    Args:
        df (pd.DataFrame): DataFrame with sentiment analysis results.
        
    Returns:
        Dict[str, Any]: Summary statistics.
    """
    # Determine which label column is being used
    label_column = None
    if "Ø§Ù„ØªØµÙ†ÙŠÙ (Label)" in df.columns:
        label_column = "Ø§Ù„ØªØµÙ†ÙŠÙ (Label)"
    elif "Label" in df.columns:
        label_column = "Label"
    
    if label_column is None:
        return {"total_items": len(df), "label_counts": {}, "avg_score": 0}
    
    # Determine which score column is being used
    score_column = None
    if "Ø§Ù„Ø«Ù‚Ø© (Score)" in df.columns:
        score_column = "Ø§Ù„Ø«Ù‚Ø© (Score)"
    elif "Score" in df.columns:
        score_column = "Score"
    
    label_counts = df[label_column].value_counts()
    avg_score = df[score_column].mean() if score_column else 0
    
    return {
        "total_items": len(df),
        "label_counts": label_counts.to_dict(),
        "avg_score": round(avg_score, 4),
        "max_score": df[score_column].max() if score_column else 0,
        "min_score": df[score_column].min() if score_column else 0
    }


def export_to_excel(df: pd.DataFrame, sheet_name: str = "Analysis Results") -> bytes:
    """
    Export analysis results to Excel format.
    
    Args:
        df (pd.DataFrame): DataFrame with analysis results.
        sheet_name (str): Name of the main data sheet.
        
    Returns:
        bytes: Excel file as bytes.
    """
    output = io.BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # Write data sheet
        df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        # Write summary sheet
        summary_stats = create_summary_stats(df)
        summary_df = pd.DataFrame({
            'Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©': [
                'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ±',
                'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©',
                'Ø£Ù‚ØµÙ‰ Ø«Ù‚Ø©',
                'Ø£Ø¯Ù†Ù‰ Ø«Ù‚Ø©',
                'ÙˆÙ‚Øª Ø§Ù„ØªØµØ¯ÙŠØ±'
            ],
            'Ø§Ù„Ù‚ÙŠÙ…Ø©': [
                summary_stats['total_items'],
                f"{summary_stats['avg_score']:.2%}",
                f"{summary_stats['max_score']:.2%}",
                f"{summary_stats['min_score']:.2%}",
                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            ]
        })
        summary_df.to_excel(writer, sheet_name='Summary', index=False)
    
    output.seek(0)
    return output.getvalue()


def save_active_learning_entry(text: str, label: str, filepath: str = "active_learning_data.csv") -> tuple[bool, str]:
    """Append a corrected (text, label) pair to a CSV file for active learning.

    Returns (success: bool, message: str)
    """
    try:
        row = {"text": text, "label": label}
        abs_path = os.path.join(os.getcwd(), filepath)

        if os.path.exists(abs_path):
            try:
                existing = pd.read_csv(abs_path)
            except Exception:
                # If file exists but cannot be read as CSV, overwrite with new
                existing = pd.DataFrame()

            new_df = pd.DataFrame([row])
            if not existing.empty:
                combined = pd.concat([existing, new_df], ignore_index=True)
            else:
                combined = new_df
            combined.to_csv(abs_path, index=False)
        else:
            pd.DataFrame([row]).to_csv(abs_path, index=False)

        return True, f"Saved to {abs_path}"
    except Exception as e:
        return False, str(e)


def main():
    """Main application function."""
    try:
        # Header
        st.markdown("<h1 class='main-header'>ğŸ“Š Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</h1>", unsafe_allow_html=True)
        st.markdown("<h3 class='main-header'>Arabic Sentiment Analysis Dashboard</h3>", unsafe_allow_html=True)
        st.markdown("---")
        
        # Sidebar configuration
        st.sidebar.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (Settings)")
        
        use_mock_data = st.sidebar.checkbox(
            "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© (Use Mock Data - Testing)",
            value=True,
            help="Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ¹"
        )
        
        # Load analyzer
        analyzer = load_analyzer()
        
        # Analysis mode selection
        st.subheader("ğŸ”„ Ù†Ù…Ø· Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Analysis Mode)")
        analysis_mode = st.radio(
            "Ø§Ø®ØªØ± Ù†Ù…Ø· Ø§Ù„ØªØ­Ù„ÙŠÙ„:",
            options=["ğŸ“± Post URL Analysis", "ğŸ·ï¸ Hashtag News Analysis"],
            horizontal=True,
            label_visibility="collapsed"
        )
        
        st.markdown("---")
        
        if analysis_mode == "ğŸ“± Post URL Analysis":
            # Original Post URL Analysis Mode
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“± Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Source)")
                post_url = st.text_input(
                    "Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†Ø´ÙˆØ± (Post URL)",
                    placeholder="https://www.facebook.com/post/123456789",
                    help="Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ù…Ù† ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ"
                )
            
            with col2:
                st.subheader("ğŸ”§ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª (Options)")
                st.write(f"**Ø§Ù„ÙˆØ¶Ø¹ (Mode):** {'ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± (Testing)' if use_mock_data else 'ğŸ”´ Ù…Ø¨Ø§Ø´Ø± (Live)'}")
            
            # Analyze button for Post URL mode
            if st.button("ğŸš€ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª (Analyze Comments)", type="primary", use_container_width=True):
                
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ù…Ù† API... (Fetching comments from API)"):
                    try:
                        # Fetch comments from the stable API
                        if use_mock_data:
                            st.info("ğŸ§ª Using local mock data for testing")
                            api_data = fetch_api_comments()
                            comments_dict = api_data
                        else:
                            st.info("ğŸŒ Fetching from external API")
                            api_data = fetch_api_comments()
                            comments_dict = api_data
                        
                        if not comments_dict:
                            st.error("âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª (Failed to fetch comments)")
                            st.stop()
                        
                        st.success(f"âœ“ ØªÙ… Ø¬Ù„Ø¨ {len(comments_dict)} ØªØ¹Ù„ÙŠÙ‚ Ø¨Ù†Ø¬Ø§Ø­")
                        
                        # Process comments
                        st.subheader("ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Analysis Results)")
                        results = process_comments(comments_dict, analyzer)
                        
                        if not results:
                            st.error("âŒ ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª (Failed to process comments)")
                            st.stop()
                        
                        # Create DataFrame
                        df = pd.DataFrame(results)
                        
                        # Display results
                        st.dataframe(df, use_container_width=True, height=400)

                        # ----------------------
                        # Manual Correction & Active Learning Feedback
                        # ----------------------
                        st.subheader("âœï¸ Manual Correction & Active Learning Feedback")
                        if not df.empty:
                            # Determine text column (comments vs news)
                            if "Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ (Comment)" in df.columns:
                                text_col = "Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ (Comment)"
                            elif "Ø§Ù„Ø®Ø¨Ø± (Headline)" in df.columns:
                                text_col = "Ø§Ù„Ø®Ø¨Ø± (Headline)"
                            else:
                                text_col = df.columns[0]

                            idx_options = df.index.tolist()
                            def _fmt(i):
                                txt = str(df.loc[i, text_col])
                                preview = txt[:80] + ("..." if len(txt) > 80 else "")
                                return f"{i} - {preview}"

                            selected_idx = st.selectbox(
                                "Ø§Ø®ØªØ± Ø§Ù„Ø³Ø·Ø± Ù„ØªØµØ­ÙŠØ­Ù‡ (Select row to correct)",
                                options=idx_options,
                                format_func=_fmt
                            )

                            original_text = str(df.loc[selected_idx, text_col])
                            st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ (Original Text)", value=original_text, height=120)

                            label_options = ["Ø¥ÙŠØ¬Ø§Ø¨ÙŠ", "Ø³Ù„Ø¨ÙŠ", "Ù…Ø­Ø§ÙŠØ¯", "Positive", "Negative", "Neutral"]
                            corrected_label = st.selectbox("Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© (Select correct label)", options=label_options)
                            custom_label = st.text_input("Ø£Ùˆ Ø£Ø¯Ø®Ù„ ØªØ³Ù…ÙŠØ© Ù…Ø®ØµØµØ© (Or enter custom label)", value="")
                            final_label = custom_label.strip() if custom_label.strip() else corrected_label

                            if st.button("ğŸ’¾ Save Correction to Training Data", key=f"save_correction_comments_{selected_idx}"):
                                ok, msg = save_active_learning_entry(original_text, final_label)
                                if ok:
                                    st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØµØ­ÙŠØ­: {final_label}")
                                else:
                                    st.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØªØµØ­ÙŠØ­: {msg}")
                        else:
                            st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶ Ø£Ùˆ Ø§Ù„ØªØµØ­ÙŠØ­ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ (No data to correct)")
                        
                        # Summary statistics
                        st.subheader("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª (Summary Statistics)")
                        stats = create_summary_stats(df)
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric(
                                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª",
                                stats['total_items']
                            )
                        
                        with col2:
                            st.metric(
                                "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©",
                                f"{stats['avg_score']:.2%}"
                            )
                        
                        with col3:
                            st.metric(
                                "Ø£Ù‚ØµÙ‰ Ø«Ù‚Ø©",
                                f"{stats['max_score']:.2%}"
                            )
                        
                        with col4:
                            st.metric(
                                "Ø£Ø¯Ù†Ù‰ Ø«Ù‚Ø©",
                                f"{stats['min_score']:.2%}"
                            )
                        
                        # Sentiment distribution
                        st.subheader("ğŸ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (Sentiment Distribution)")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            sentiment_counts = df["Ø§Ù„ØªØµÙ†ÙŠÙ (Label)"].value_counts()
                            st.bar_chart(sentiment_counts)
                        
                        with col2:
                            # Summary table
                            fig_data = {
                                'Ø§Ù„ØªØµÙ†ÙŠÙ': sentiment_counts.index,
                                'Ø§Ù„Ø¹Ø¯Ø¯': sentiment_counts.values
                            }
                            fig_df = pd.DataFrame(fig_data)
                            st.write(fig_df)
                        
                        # Export to Excel
                        st.subheader("ğŸ’¾ Ø§Ù„ØªØµØ¯ÙŠØ± (Export)")
                        
                        excel_data = export_to_excel(df, sheet_name="Comments Analysis")
                        st.download_button(
                            label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Download Results as Excel)",
                            data=excel_data,
                            file_name=f"comments_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                        
                    except Exception as e:
                        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}")
                        st.error("Error Details:")
                        st.code(traceback.format_exc())
        
        else:  # Hashtag News Analysis Mode
            st.subheader("ğŸ·ï¸ ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù‡Ø§Ø´ØªØ§Øº (Hashtag News Analysis)")
            
            # Show available topics
            st.info("ğŸ“š **Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© (Available Topics):**\n\n"
                    "ğŸ‡®ğŸ‡¶ **Ø¨ØºØ¯Ø§Ø¯** (Baghdad) | ğŸ’° **Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯** (Economy) | ğŸ–¥ï¸ **Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§** (Technology) | "
                    "âš½ **Ø§Ù„Ø±ÙŠØ§Ø¶Ø©** (Sports) | ğŸ¥ **Ø§Ù„ØµØ­Ø©** (Health)")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                hashtag_query = st.text_input(
                    "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù‡Ø§Ø´ØªØ§Øº Ø£Ùˆ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ (Enter Hashtag/Topic)",
                    placeholder="Ø¨ØºØ¯Ø§Ø¯ / Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ / Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§",
                    help="Ù…Ø«Ø§Ù„: #Ø¨ØºØ¯Ø§Ø¯ Ø£Ùˆ Ø¨ØºØ¯Ø§Ø¯ (Ø§Ù„Ù‡Ø§Ø´ØªØ§Øº Ø§Ø®ØªÙŠØ§Ø±ÙŠ)"
                )
            
            with col2:
                st.write(f"**Ø§Ù„ÙˆØ¶Ø¹ (Mode):** ğŸ§ª Mock Data")
            
            # Analyze button for Hashtag mode
            if st.button("ğŸš€ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (Analyze News)", type="primary", use_container_width=True):
                
                if not hashtag_query or not hashtag_query.strip():
                    st.error("âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù‡Ø§Ø´ØªØ§Øº Ø£Ùˆ Ù…ÙˆØ¶ÙˆØ¹ (Please enter a hashtag)")
                    st.warning("ğŸ’¡ Ø¬Ø±Ø¨ Ø£Ø­Ø¯ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø£Ø¹Ù„Ø§Ù‡")
                else:
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©... (Fetching news)"):
                        try:
                            # Fetch news articles for hashtag
                            articles = scrape_hashtag_news(hashtag_query.strip())
                            
                            if not articles or len(articles) == 0:
                                st.error(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹: {hashtag_query}")
                                st.error("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¬Ø±Ø¨ Ø£Ø­Ø¯ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:\n"
                                        "â€¢ Ø¨ØºØ¯Ø§Ø¯\n"
                                        "â€¢ Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯\n"
                                        "â€¢ Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§\n"
                                        "â€¢ Ø§Ù„Ø±ÙŠØ§Ø¶Ø©\n"
                                        "â€¢ Ø§Ù„ØµØ­Ø©")
                                st.stop()
                            
                            st.success(f"âœ“ ØªÙ… Ø¬Ù„Ø¨ {len(articles)} Ø®Ø¨Ø± Ø¹Ù†: {hashtag_query}")
                            
                            # Process articles
                            st.subheader("ğŸ“° Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Analysis Results)")
                            results = process_news_articles(articles, analyzer)
                            
                            if not results:
                                st.error("âŒ ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (Failed to process articles)")
                                st.stop()
                            
                            # Create DataFrame
                            df = pd.DataFrame(results)
                            
                            # Display results
                            st.dataframe(df, use_container_width=True, height=400)

                            # ----------------------
                            # Manual Correction & Active Learning Feedback
                            # ----------------------
                            st.subheader("âœï¸ Manual Correction & Active Learning Feedback")
                            if not df.empty:
                                # Determine text column (comments vs news)
                                if "Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ (Comment)" in df.columns:
                                    text_col = "Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ (Comment)"
                                elif "Ø§Ù„Ø®Ø¨Ø± (Headline)" in df.columns:
                                    text_col = "Ø§Ù„Ø®Ø¨Ø± (Headline)"
                                else:
                                    text_col = df.columns[0]

                                idx_options = df.index.tolist()
                                def _fmt(i):
                                    txt = str(df.loc[i, text_col])
                                    preview = txt[:80] + ("..." if len(txt) > 80 else "")
                                    return f"{i} - {preview}"

                                selected_idx = st.selectbox(
                                    "Ø§Ø®ØªØ± Ø§Ù„Ø³Ø·Ø± Ù„ØªØµØ­ÙŠØ­Ù‡ (Select row to correct)",
                                    options=idx_options,
                                    format_func=_fmt
                                )

                                original_text = str(df.loc[selected_idx, text_col])
                                st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ (Original Text)", value=original_text, height=120)

                                label_options = ["Ø¥ÙŠØ¬Ø§Ø¨ÙŠ", "Ø³Ù„Ø¨ÙŠ", "Ù…Ø­Ø§ÙŠØ¯", "Positive", "Negative", "Neutral"]
                                corrected_label = st.selectbox("Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© (Select correct label)", options=label_options)
                                custom_label = st.text_input("Ø£Ùˆ Ø£Ø¯Ø®Ù„ ØªØ³Ù…ÙŠØ© Ù…Ø®ØµØµØ© (Or enter custom label)", value="")
                                final_label = custom_label.strip() if custom_label.strip() else corrected_label

                                if st.button("ğŸ’¾ Save Correction to Training Data", key=f"save_correction_news_{selected_idx}"):
                                    ok, msg = save_active_learning_entry(original_text, final_label)
                                    if ok:
                                        st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØµØ­ÙŠØ­: {final_label}")
                                    else:
                                        st.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØªØµØ­ÙŠØ­: {msg}")
                            else:
                                st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶ Ø£Ùˆ Ø§Ù„ØªØµØ­ÙŠØ­ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ (No data to correct)")
                            
                            # Summary statistics
                            st.subheader("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª (Summary Statistics)")
                            stats = create_summary_stats(df)
                            
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric(
                                    "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±",
                                    stats['total_items']
                                )
                            
                            with col2:
                                st.metric(
                                    "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©",
                                    f"{stats['avg_score']:.2%}"
                                )
                            
                            with col3:
                                st.metric(
                                    "Ø£Ù‚ØµÙ‰ Ø«Ù‚Ø©",
                                    f"{stats['max_score']:.2%}"
                                )
                            
                            with col4:
                                st.metric(
                                    "Ø£Ø¯Ù†Ù‰ Ø«Ù‚Ø©",
                                    f"{stats['min_score']:.2%}"
                                )
                            
                            # Sentiment distribution
                            st.subheader("ğŸ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (Sentiment Distribution)")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                sentiment_counts = df["Ø§Ù„ØªØµÙ†ÙŠÙ (Label)"].value_counts()
                                st.bar_chart(sentiment_counts)
                            
                            with col2:
                                # Summary table
                                fig_data = {
                                    'Ø§Ù„ØªØµÙ†ÙŠÙ': sentiment_counts.index,
                                    'Ø§Ù„Ø¹Ø¯Ø¯': sentiment_counts.values
                                }
                                fig_df = pd.DataFrame(fig_data)
                                st.write(fig_df)
                            
                            # Export to Excel
                            st.subheader("ğŸ’¾ Ø§Ù„ØªØµØ¯ÙŠØ± (Export)")
                            
                            excel_data = export_to_excel(df, sheet_name="News Analysis")
                            st.download_button(
                                label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Download Results as Excel)",
                                data=excel_data,
                                file_name=f"news_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                            
                        except Exception as e:
                            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}")
                            st.error("Error Details:")
                            st.code(traceback.format_exc())
        
        # Footer
        st.markdown("---")
        st.markdown("""
            <div style='text-align: center; color: gray; font-size: 0.8rem;'>
            <p>Arabic Sentiment Analysis Dashboard v2.0</p>
            <p>Ù…Ø¹ Ø¯Ø¹Ù… ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù‡Ø§Ø´ØªØ§Øº | With Hashtag News Analysis Support</p>
            </div>
        """, unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"âŒ Critical Application Error: {str(e)}")
        st.error(traceback.format_exc())
        st.stop()


if __name__ == "__main__":
    main()
